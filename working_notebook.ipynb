{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64857d6f-ddcc-4822-ad07-2f808e95287f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3bc54b0-b766-4298-b00a-dd11fe2ae007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import NounParser,VerbParser,AdjectiveNumeralParser\n",
    "import pandas as pd\n",
    "from lingpy import *\n",
    "from segments.tokenizer import Tokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85adf0b1-2150-4b58-80a8-bb4455a37e38",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb833300-8803-411f-b6bb-a08485a36295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Instantiating parser objects\n",
    "noun_parser=NounParser()\n",
    "verb_parser=VerbParser()\n",
    "adj_num_parser=AdjectiveNumeralParser()\n",
    "\n",
    "\n",
    "def prior_forms(row):\n",
    "    \"\"\"\n",
    "    puts all forms that have been parsed into a single column\n",
    "    \"\"\"\n",
    "    if pd.isna(row[\"POS\"]):  \n",
    "        return None\n",
    "    elif row[\"POS\"] in [\"noun\", \"numeral\", \"adjective\"]:\n",
    "        form = str(row[\"SINGULAR\"]) if isinstance(row[\"SINGULAR\"], str) else \"\"\n",
    "        return form\n",
    "    elif row[\"POS\"] == \"verb\":\n",
    "        verb = row[\"FORM\"]\n",
    "        if pd.isna(verb):\n",
    "            return None\n",
    "        else:\n",
    "            return verb\n",
    "    else:\n",
    "        form = str(row[\"SINGULAR\"]) if isinstance(row[\"SINGULAR\"], str) else \"\"\n",
    "        return form\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_data(row):\n",
    "    \"\"\"\n",
    "    Parses data and places parsed data into one column.\n",
    "    \"\"\"\n",
    "    if pd.isna(row[\"POS\"]):  \n",
    "        return None\n",
    "    elif row[\"POS\"] == \"noun\":\n",
    "        noun = row[\"IPA\"]\n",
    "        if pd.isna(noun):\n",
    "            return None\n",
    "        parsed_noun = (noun_parser.identified_suffixes(\n",
    "            noun_parser.hyphen_space(\n",
    "                noun_parser.nasalized_stops(\n",
    "                    noun_parser.cvcv_segmentation(\n",
    "                        noun_parser.parse_noun_durationals(\n",
    "                            noun_parser.parse_off_final_nasals(\n",
    "                                noun_parser.existing_parses(\n",
    "                                    adj_num_parser.y_suffixes(noun.strip(\"()/_\")))))))))) if (noun.endswith(\"y\") or (noun.endswith(\"ⁿ\") and noun[-2]==\"y\")) else \\\n",
    "                            (noun_parser.identified_suffixes(\n",
    "                                noun_parser.hyphen_space(\n",
    "                                    noun_parser.nasalized_stops(\n",
    "                                        noun_parser.cvcv_segmentation(\n",
    "                                            noun_parser.parse_noun_durationals(\n",
    "                                                noun_parser.parse_off_final_nasals(\n",
    "                                                    noun_parser.existing_parses(noun.strip(\"()/_\")))))))))\n",
    "        return parsed_noun\n",
    "    elif row[\"POS\"] == \"verb\":\n",
    "        verb = row[\"IPA\"]\n",
    "        if pd.isna(verb):\n",
    "            return None\n",
    "        parsed_verb = verb_parser.post_editing_short_strings(\n",
    "            verb_parser.segment_cvcs(\n",
    "                verb_parser.parse_verb_durationals(\n",
    "                    verb_parser.existing_parses(verb.strip(\")(_\")))))\n",
    "        return parsed_verb\n",
    "    elif row[\"POS\"] == \"numeral\" or row[\"POS\"] == \"adjective\":\n",
    "        adjective_numeral = str(row[\"IPA\"]) if isinstance(row[\"IPA\"], str) else \"\"\n",
    "        if pd.isna(adjective_numeral):\n",
    "            return None\n",
    "        parsed_adj_num = adj_num_parser.miscellaneous(\n",
    "            adj_num_parser.switch_hyphen_position(\n",
    "                adj_num_parser.replace_hyphens_keep_last(\n",
    "                    adj_num_parser.y_suffixes(\n",
    "                        adj_num_parser.isolating_suffixes(\n",
    "                            adj_num_parser.parse_verb_durationals(\n",
    "                                adj_num_parser.existing_parses(adjective_numeral.strip(\"()/_\"))))))))\n",
    "        return parsed_adj_num\n",
    "    elif row[\"POS\"] in [\"pronoun\", \"other\"]:\n",
    "        form = row[\"IPA\"]\n",
    "        return noun_parser.parse_noun_durationals(noun_parser.existing_parses(form))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def data_prep_for_ortho_profile(input_file):\n",
    "    \"\"\"\n",
    "    prepares data so that command line can run on it to output an orthography profile\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_file, delimiter='\\t')\n",
    "    df[\"ID\"]=df[\"ID\"].astype(str)\n",
    "    df['ID'] = pd.to_numeric(df['ID'].str.replace(',', '').str.replace('.', ''), errors='coerce')\n",
    "    df = df.dropna(subset=['ID'])\n",
    "    df['ID'] = df['ID'].astype(int)\n",
    "    return df.to_csv('heathdogon2.tsv', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "def add_tab_after_quote(input_file, output_file, encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    creates a tsv file in which quotation characters are eliminated\n",
    "    input_file: orthography profile created via the command line: $ lingpy profile -i heathdogon2.tsv -o  P_created-profile.tsv --column=ipa\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r', encoding=encoding) as infile, open(output_file, 'w', encoding=encoding) as outfile:\n",
    "        for line in infile:\n",
    "            new_line = ''\n",
    "            quote_added = False\n",
    "            for char in line:\n",
    "                if char == '\"':\n",
    "                    new_line += char + '\\t'\n",
    "                    quote_added = True\n",
    "                else:\n",
    "                    new_line += char\n",
    "                    if quote_added:\n",
    "                        quote_added = False\n",
    "            outfile.write(new_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0081d-f70a-4616-9c26-94976ed05266",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c4d1552-b1f0-496a-a4e6-8535912ef663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "pd.set_option('display.max_rows', None)\n",
    "path = r\"D:\\ERC_Bang\\Tasks\\data_cleaning\" \n",
    "os.chdir(path)\n",
    "data = pd.read_csv(\"data.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "list_to_drop=[\"FRENCH\", \"ENGLISH_SHORT\", \"FRENCH_SHORT\", \"ENGLISH_CATEGORY\", \"FRENCH_CATEGORY\", \"PARSED FORM\", \"MCF\", \"RECONSTRUCTION\", \"NOTE\", \"NOTES\",\"Unnamed: 18\", \"Unnamed: 19\", \"Unnamed: 20\", \"Unnamed: 21\", \"COGID\", \"COGIDS\", \"Unnamed: 24\"]\n",
    "data=data.drop(list_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ad04aa7-da60-430c-a8dc-9f611f8d1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting all data parsable data into one columns\n",
    "data[\"BEFORE_PARSE\"]=data.apply(prior_forms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bf0ee2b-9318-4f84-bafd-fca0d883fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating orthography profile\n",
    "op=Tokenizer(\"output.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ee71ce2-cb7b-48c7-a0b1-0a3885286800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying orthography profile\n",
    "data[\"IPA\"]=data[\"BEFORE_PARSE\"].apply(lambda x: op(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a92cef8-7d4b-4118-8e28-ebba1b164947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing data\n",
    "data[\"PARSED\"]=data.apply(parse_data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08e5cdef-effc-427d-a535-81bb02684105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jáw-dì-m\n",
       "1        dáábà-m\n",
       "2      àrsɛ̌ɛ̌-m\n",
       "3       kɔ́-mbɔ̀\n",
       "4       bɛ́lɛ̀-g\n",
       "5      bɛ́lɛ̀-gù\n",
       "6          bɛ̀lú\n",
       "7          bɛ̀lú\n",
       "8    gàr sɛ̀-gɛ́\n",
       "9      à sɛ̀-gɛ́\n",
       "Name: PARSED, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PARSED\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ececfaaa-407d-4076-b957-d05d564efb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Parsed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11f735-4dac-4e69-b262-d4a515efdb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
