{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64857d6f-ddcc-4822-ad07-2f808e95287f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3bc54b0-b766-4298-b00a-dd11fe2ae007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import NounParser,VerbParser,AdjectiveNumeralParser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85adf0b1-2150-4b58-80a8-bb4455a37e38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cb833300-8803-411f-b6bb-a08485a36295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Instantiating parser objects\n",
    "noun_parser=NounParser()\n",
    "verb_parser=VerbParser()\n",
    "adj_num_parser=AdjectiveNumeralParser()\n",
    "\n",
    "\n",
    "def prior_forms(row):\n",
    "    \"\"\"\n",
    "    puts all forms that have been parsed into a single column\n",
    "    \"\"\"\n",
    "    if pd.isna(row[\"POS\"]):  \n",
    "        return None\n",
    "    elif row[\"POS\"] in [\"noun\", \"numeral\", \"adjective\"]:\n",
    "        form = str(row[\"SINGULAR\"]) if isinstance(row[\"SINGULAR\"], str) else \"\"\n",
    "        return form\n",
    "    elif row[\"POS\"] == \"verb\":\n",
    "        verb = row[\"FORM\"]\n",
    "        if pd.isna(verb):\n",
    "            return None\n",
    "        else:\n",
    "            return verb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_data(row):\n",
    "    \"\"\"\n",
    "    parses data and places parsed data into one column\n",
    "    \"\"\"\n",
    "    if pd.isna(row[\"POS\"]):  \n",
    "        return None\n",
    "    elif row[\"POS\"] == \"noun\":\n",
    "        noun = row[\"SINGULAR\"]\n",
    "        if pd.isna(noun):\n",
    "            return None\n",
    "        return noun_parser.identified_suffixes(\n",
    "            noun_parser.hyphen_space(\n",
    "                noun_parser.nasalized_stops(\n",
    "                    noun_parser.cvcv_segmentation(\n",
    "                        noun_parser.second_parse_durationals(\n",
    "                            noun_parser.first_parse_durationals(\n",
    "                                noun_parser.existing_parses(\n",
    "                                    adj_num_parser.y_suffixes(noun.strip(\"()/_\"))))))))) if noun.endswith(\"y\") or (noun.endswith(\"ⁿ\") and noun[-2]==\"y\") else noun_parser.identified_suffixes(\n",
    "            noun_parser.hyphen_space(\n",
    "                noun_parser.nasalized_stops(\n",
    "                    noun_parser.cvcv_segmentation(\n",
    "                        noun_parser.second_parse_durationals(\n",
    "                            noun_parser.first_parse_durationals(\n",
    "                                noun_parser.existing_parses(noun.strip(\"()/_\")))))))) \n",
    "    elif row[\"POS\"] == \"verb\":\n",
    "        verb = row[\"FORM\"]\n",
    "        if pd.isna(verb):\n",
    "            return None\n",
    "        return verb_parser.post_editing_short_strings(\n",
    "            verb_parser.segment_cvcs(\n",
    "                verb_parser.second_parse_durationals(\n",
    "                    verb_parser.first_parse_durationals(\n",
    "                        verb_parser.existing_parses(verb.strip(\")(_\"))))))\n",
    "    elif row[\"POS\"] == \"numeral\" or row[\"POS\"] == \"adjective\":\n",
    "        adjective_numeral = str(row[\"SINGULAR\"]) if isinstance(row[\"SINGULAR\"], str) else \"\"\n",
    "        if pd.isna(adjective_numeral):\n",
    "            return None\n",
    "        return adj_num_parser.miscellaneous(\n",
    "            adj_num_parser.switch_hyphen_position(\n",
    "                adj_num_parser.replace_hyphens_keep_last(\n",
    "                    adj_num_parser.y_suffixes(\n",
    "                        adj_num_parser.isolating_suffixes(\n",
    "                            adj_num_parser.second_parse_durationals(\n",
    "                                adj_num_parser.first_parse_durationals(\n",
    "                                    adj_num_parser.existing_parses(adjective_numeral.strip(\"()/_\")))))))))\n",
    "    elif row[\"POS\"] in [\"pronoun\", \"other\"]:\n",
    "        form=row[\"SINGULAR\"]\n",
    "        return form\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0081d-f70a-4616-9c26-94976ed05266",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5c4d1552-b1f0-496a-a4e6-8535912ef663",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "path = r\"D:\\ERC_Bang\\Tasks\\data_cleaning\" \n",
    "os.chdir(path)\n",
    "data = pd.read_csv(\"data.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "list_to_drop=[\"FRENCH\", \"ENGLISH_SHORT\", \"FRENCH_SHORT\", \"ENGLISH_CATEGORY\", \"FRENCH_CATEGORY\", \"PARSED FORM\", \"MCF\", \"RECONSTRUCTION\", \"NOTE\", \"NOTES\",\"Unnamed: 18\", \"Unnamed: 19\", \"Unnamed: 20\", \"Unnamed: 21\", \"COGID\", \"COGIDS\", \"Unnamed: 24\"]\n",
    "data=data.drop(list_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3ad04aa7-da60-430c-a8dc-9f611f8d1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"BEFORE_PARSE\"]=data.apply(prior_forms, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fc0a24f9-4053-413d-882a-420461eab4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jáwdì-m\n",
       "1       dá:bà-m\n",
       "2      àrsɛ̌:-m\n",
       "3       kɔ́mbɔ̀\n",
       "4      bɛ́lɛ̀-g\n",
       "5     bɛ́lɛ̀-gù\n",
       "6         bɛ̀lú\n",
       "7         bɛ̀lú\n",
       "8    gàr sɛ̀gɛ́\n",
       "9      à sɛ̀gɛ́\n",
       "Name: BEFORE_PARSE, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"BEFORE_PARSE\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ea576efe-f952-49a7-be8a-9ae7efcea988",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PARSED'] = data.apply(parse_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48f452ef-38f3-4040-ae74-b0d3e32ceb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jáw-dì-m\n",
       "1        dáábà-m\n",
       "2       àrsɛ̌ɛ-m\n",
       "3       kɔ́-mbɔ̀\n",
       "4       bɛ́lɛ̀-g\n",
       "5      bɛ́lɛ̀-gù\n",
       "6          bɛ̀lú\n",
       "7          bɛ̀lú\n",
       "8    gàr sɛ̀-gɛ́\n",
       "9      à sɛ̀-gɛ́\n",
       "Name: PARSED, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PARSED\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a461a8e3-38d8-4566-8c65-d126fd558382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"second_parse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841101c-16f7-497d-a028-06bb461bf1a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb907d0f-0ac1-41b1-ae2b-d8f894264655",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns= data[data[\"SINGULAR\"].notna()][\"SINGULAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c703957-ba33-4181-95b0-6243f2070457",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_parser=NounParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c275fc4-f560-42ea-9910-d28177bd0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_parsed = nouns.apply(lambda x: adj_num_parser.y_suffixes(x) if x.endswith(\"y\") or (x.endswith(\"ⁿ\") and x[-2]==\"y\") else x).apply(\n",
    "    lambda x: noun_parser.first_parse_durationals(x)).apply(\n",
    "    lambda x: noun_parser.second_parse_durationals(x)).apply(\n",
    "    lambda x: noun_parser.cvcv_segmentation(x)).apply(\n",
    "    lambda x: noun_parser.nasalized_stops(x)).apply(\n",
    "    lambda x: noun_parser.hyphen_space(x)).apply(\n",
    "    lambda x: noun_parser.identified_suffixes(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f809acc8-c2fc-4824-a934-b3e6e91ae61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jáw-dì-m\n",
       "1        dáábà-m\n",
       "2       àrsɛ̌ɛ-m\n",
       "3       kɔ́-mbɔ̀\n",
       "4       bɛ́lɛ̀-g\n",
       "5      bɛ́lɛ̀-gù\n",
       "6          bɛ̀lú\n",
       "7          bɛ̀lú\n",
       "8    gàr sɛ̀-gɛ́\n",
       "9      à sɛ̀-gɛ́\n",
       "Name: SINGULAR, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_parsed[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7624e24-3d01-4c3e-b91f-85f251bdd78f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b941ea50-8016-4706-aafe-dfdc3fd63de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerbParser(NounParser):\n",
    "    def __init__(self):\n",
    "       super().__init__()\n",
    "        \n",
    "    def consonant_count(self, item):\n",
    "        \"\"\"\n",
    "        counts number of consonants in words\n",
    "        \"\"\"\n",
    "        \n",
    "        if item is None:\n",
    "            return 0\n",
    "        \n",
    "        consonant_count=0\n",
    "        for letter in item:\n",
    "            if letter != \"ⁿ\" and letter in self.consonants:\n",
    "                consonant_count +=1\n",
    "        return consonant_count\n",
    "                      \n",
    "\n",
    "    def first_parse_durationals(self, item):\n",
    "        \"\"\"Double cases where a vowel has durataional marking\"\"\"\n",
    "      \n",
    "        def get_last_vowel(item):\n",
    "            \"\"\"Extracts the last vowel from the input string ending with ':'\"\"\"\n",
    "            if item.endswith(\":\") or item.endswith(\":\"):\n",
    "                return item[-2]\n",
    "            return None\n",
    "\n",
    "        vowels = [get_last_vowel(item)] # extracting vowels \n",
    "        for letter in self.replacements:     # Handle exceptions like 'tɔ́d-ɛ̀:' and 'nàrⁿ-ɛ́:'\n",
    "            if item.endswith(letter + ':') or item.endswith(letter + \":\"):\n",
    "                word= item[:-1] + \"-\" + self.replacements[letter]\n",
    "            else:\n",
    "                word=item\n",
    "\n",
    "        if 'ɛ᷈:' in item:                # Handle the exceptional case 'jɛ᷈:'\n",
    "            word=item[:-1] + \"-ɛ᷈\"\n",
    "\n",
    "        else:\n",
    "            word= item\n",
    "\n",
    "        for letter in self.replacements:     # Handle cases of unextracted vowels\n",
    "            if word.endswith(\":\") or word.endswith(\":\"):\n",
    "                if letter in word[1:4]:\n",
    "                    return word[:-1] + \"-\" + self.replacements[letter]\n",
    "        material = self.extra_material.get(vowels[0], vowels[0])\n",
    "        \n",
    "        return self.second_parse_durationals(word[:-1] + \"-\" + material if vowels[0] else word)\n",
    "\n",
    "    def second_parse_durationals(self, word):\n",
    "            \"\"\"\n",
    "            normal parsing of durationals by doubling the vowel with the durational feature. This is neccesary to ensure no leftovers from first parse\n",
    "            \"\"\"\n",
    "        \n",
    "            new_word=\"\"\n",
    "            for index, letter in enumerate(word):\n",
    "                idx=len(word)-index\n",
    "                if letter==\":\" or letter==\":\" and idx !=0:\n",
    "                    letter=f\"{self.replacements.get(word[index -1],word[index -1])}\"\n",
    "                    new_word += letter\n",
    "                elif letter==\":\" or letter==\":\" and idx ==0:\n",
    "                    letter=f\"-{self.replacements.get(word[index -1],word[index -1])}\"\n",
    "                    new_word += letter  \n",
    "                else:\n",
    "                    new_word +=letter\n",
    "            return new_word.replace(\"--\", \"-\")\n",
    "\n",
    "    def post_editing_short_strings(self, word):\n",
    "        \"\"\"\n",
    "        post edits short words that have been \"over-parsed\" as a result of issues encountered with character fonts\n",
    "        \"\"\"\n",
    "        \n",
    "        if word is None:\n",
    "            return None\n",
    "        \n",
    "        consonant_count=self.consonant_count(word)\n",
    "        if consonant_count <=2 and word.count(\"-\") >1:\n",
    "            word=word.replace(\"-\", \"\", 1)\n",
    "        return word\n",
    "        \n",
    "    def hyphen_space(self, word):\n",
    "        \"\"\"\n",
    "        special utility function to remove hyphens after morphemic boundaries indicated by a space and hyphens occurring word initially\n",
    "        \"\"\"\n",
    "        new_word=\"\"\n",
    "        for index, letter in enumerate(word):\n",
    "            if letter== \"-\" and index+1 < len(word) and (word[index+1]== \" \" or word[index-1]== \" \") :\n",
    "                new_word += \"\"\n",
    "            else:\n",
    "                new_word +=  letter\n",
    "        return new_word\n",
    "\n",
    "    \n",
    "    def maintaining_nasality_on_segment(self, word):\n",
    "        \"\"\"\n",
    "        ensures that nasality remains on segment that is marked for it, and also parses sounds occuring after the nasal marker  \n",
    "        \"\"\"\n",
    "        new_word=\"\"\n",
    "        for index, letter in enumerate(word):\n",
    "            if letter == \"-\" and index + 1 < len(word) and word[index + 1]== \"ⁿ\":         #solve zǐǐ-ⁿ zǐ-ǐⁿ from here\n",
    "                new_word +=\"\"\n",
    "            else:\n",
    "                new_word += letter\n",
    "    \n",
    "        word=\"\"\n",
    "        for index, letter in enumerate(new_word):\n",
    "            idx=len(new_word)-index\n",
    "            if letter == \"ⁿ\" and 3 >= idx > 1:\n",
    "                if new_word[index]!= \"-\":\n",
    "                    word += f\"{letter}-\"\n",
    "    \n",
    "            else:\n",
    "                word +=letter\n",
    "        \n",
    "        if \"-\" not in word:\n",
    "            new_word=\"\"\n",
    "            for index, letter in enumerate(word):\n",
    "                if letter not in self.consonants and index+1 < len(word) and \"ⁿ\" in word[index: index+2]:\n",
    "                    new_word += f\"-{letter}\"\n",
    "                else:\n",
    "                    new_word +=letter\n",
    "            return self.hyphen_space(new_word)\n",
    "        else:       \n",
    "            return self.hyphen_space(word)\n",
    "        \n",
    "\n",
    "    def verify_exceptions(self, word):\n",
    "        \"\"\"\n",
    "        verifies that consonant ensembles are not parsed as different consonants and reparses long words with consonant ensembles\n",
    "        \"\"\"\n",
    "        for i in self.exceptions:\n",
    "            with_hyphen = i[0] + \"-\" + i[1]\n",
    "            if with_hyphen in word:\n",
    "                idx = word.index(with_hyphen)\n",
    "                word = word[:idx] + i + \"-\" + word[idx + 3:]\n",
    "            else:\n",
    "                word=word\n",
    "        word = word.replace(\"--\", \"-\")\n",
    "        \n",
    "        return self.maintaining_nasality_on_segment(word)\n",
    "            \n",
    "\n",
    "    def vowel_tone_hyphen(self, word):\n",
    "        \"\"\"\n",
    "        handles cases in which despite parse_durationals, it is difficult to extract vowels\n",
    "        \"\"\"\n",
    "        if len(word) >= 4:\n",
    "            if word[-1] not in self.vowels.union(self.consonants) and word[-2] == \"-\":\n",
    "                return self.verify_exceptions(word[:-3] + \"-\" + word[-3] + word[-1]) \n",
    "        return self.verify_exceptions(word)\n",
    "\n",
    "    def syllabic_vowels(self, word):\n",
    "        \"\"\"\n",
    "        isolates syllabic vowels and parses them off\n",
    "        \"\"\"\n",
    "        final_word = word\n",
    "\n",
    "        for alphabet in self.vowels:\n",
    "            if alphabet in word[2:-2]:\n",
    "                try:\n",
    "                    index = word.index(alphabet)\n",
    "                    if word[index - 1] == \"-\" and word[index + 1] in self.consonants:\n",
    "                        final_word = final_word.replace(word[index], f\"{alphabet}-\")\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        return self.vowel_tone_hyphen(final_word.rstrip('-').replace(\"--\", \"-\"))\n",
    "\n",
    "    def post_coda(self, word):\n",
    "        \"\"\"\n",
    "        parses vowels sounds that occur after codas\n",
    "        \"\"\"\n",
    "        for i in range(1, len(word) - 3):\n",
    "            if word[i] in self.consonants:\n",
    "                if i + 1 < len(word) and word[i + 1] == \"-\":\n",
    "                    try:\n",
    "                        if i + 2 < len(word) and i + 3 < len(word) and word[i + 2] in self.vowels and word[\n",
    "                            i + 3] in self.consonants:\n",
    "                            material = word[:i + 2] + \"-\" + word[i + 2:]\n",
    "                            return self.syllabic_vowels(material)\n",
    "                        else:\n",
    "                            return self.syllabic_vowels(word)\n",
    "                    except IndexError:\n",
    "                        return self.syllabic_vowels(word)\n",
    "        return self.syllabic_vowels(word)\n",
    "\n",
    "    def special_mid_forms(self, item):\n",
    "        \"\"\"\n",
    "        takes words of between 3-4 alphabets long that have special characters and parses them\n",
    "        \"\"\"\n",
    "        if \"-\" not in item[-3:] and item[-1] not in self.consonants:\n",
    "            return self.post_coda(item[:-1] + \"-\" + item[-1:])\n",
    "        return self.post_coda(item)\n",
    "\n",
    "    def special_long_words(self, word):\n",
    "        \"\"\"\n",
    "        takes word of length 5 and parses them into CVC: this is because of the font-recognition issues encountered\n",
    "        \"\"\"\n",
    "        current_syllable = ''\n",
    "        consonant_count = 0\n",
    "\n",
    "        for i in range(len(word)):\n",
    "            if word[i] != \"ⁿ\" and word[i] in self.consonants:\n",
    "                consonant_count += 1\n",
    "                if consonant_count == 2 and i < len(word):\n",
    "                    word = word[:i + 1] + '-' + word[i + 1:]\n",
    "                    consonant_count = 0\n",
    "        return self.post_coda(word)\n",
    "   \n",
    "    \n",
    "    def long_words(self, word):\n",
    "        \"\"\"\n",
    "        parses long words according to a cvc priority structure and also takes care of idiosyncratic words\n",
    "        \"\"\"\n",
    "        num=[2,4,6,8]\n",
    "        new_word=\"\" #word parsed according to cvc priority\n",
    "        consonant_count=0\n",
    "        for index, letter in enumerate(word):\n",
    "            \n",
    "            if letter == \" \" or letter== \"ⁿ\":\n",
    "                consonant_count=0\n",
    "                new_word +=letter\n",
    "                \n",
    "            elif letter!= \"ⁿ\" and letter in self.consonants: #just to be extra sure\n",
    "                consonant_count +=1\n",
    "                if consonant_count in num:\n",
    "                    new_word += f\"{letter}-\"\n",
    "                elif consonant_count==3 and word[index-1] != \" \":\n",
    "                    new_word +=f\"-{letter}\"\n",
    "                else:\n",
    "                    new_word += letter\n",
    "                    \n",
    "            else:\n",
    "                new_word +=letter\n",
    "    \n",
    "        if \" \"  in new_word and \"-\" not in new_word[new_word.index(\" \"):]:   #parsing words such as \"gúr-ɔ́ gùrɔ́\" which have second parts not responding to code above so they become \"gúr-ɔ́ gùr-ɔ́\"\n",
    "            consonant_count=self.consonant_count(new_word[new_word.index(\" \"):])\n",
    "            if consonant_count >=2 and new_word[-1] not in self.consonants:\n",
    "                conso=[x for x in new_word[new_word.index(\" \"):] if x in self.consonants]\n",
    "                idx=new_word.index(conso[1])\n",
    "                new_word=new_word[:idx+1] + \"-\" + new_word[idx+1:] \n",
    "        \n",
    "        new_word=new_word[:-1].replace(\"--\", \"-\") if new_word[-1] == '-' else new_word.replace(\"--\", \"-\")\n",
    " \n",
    "        return self.verify_exceptions(new_word)\n",
    "\n",
    "\n",
    "    \n",
    "    def segment_cvcs(self, item):\n",
    "        \"\"\"\n",
    "        main segmentation function to be implemented after parse_durationals has been implemented\n",
    "        \"\"\"\n",
    "        if len(item) >= 5:\n",
    "            return self.long_words(item)\n",
    "        elif 3 <= len(item) <= 4:\n",
    "            return self.special_mid_forms(item) #calling special_mid_forms function\n",
    "        else:\n",
    "            return self.post_coda(item) #directly sending words to post_coda function for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "25c25bca-3fad-4563-9110-8ba41d3dbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs=data[data[\"FORM\"].notna()][\"FORM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "997acbf9-1b11-4559-a202-6655342ab532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verb_parser=VerbParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bb79ea76-5f38-4181-859a-772e7c80da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_parsed= (verbs\n",
    "    .apply(verb_parser.existing_parses)\n",
    "    .apply(verb_parser.first_parse_durationals)\n",
    "    .apply(verb_parser.segment_cvcs)\n",
    "    .apply(verb_parser.post_editing_short_strings)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "47676a69-2c09-4ffc-80b9-d0fc51d7ce86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2736                        jìr-é kím-jɛ́\n",
       "2737                       gìr-ó kɛ́m-sɛ̀\n",
       "2738          gìr-ù kúm-ò-lò kùm-ò-lò kán\n",
       "2739                               kám-ɲá\n",
       "2740                  kúm-ɛ́ kúm-ɛ́ kán-í\n",
       "2741                  mìj-ɛ̀ mìj-ɛ̀ kán-í\n",
       "2742                gìr-è ɲɛ́m-ɛ́-lɛ́ kán\n",
       "2743                              kɛ́m-jí\n",
       "2744                                kám-í\n",
       "2745                              cíwⁿ-ɛ́\n",
       "2746                     gìr-è kám-dá kán\n",
       "2747        jír-ó kùmb-ì yò kùm-bì lè kán\n",
       "2748                            kúm-ú-ɲɔ́\n",
       "2749                     gìr-é kúm-ú-nj-ó\n",
       "2750    jìr-iⁿ kúm-ú-jɛ̀ kúm-ú-jɛ̀ bìr-ɛ̀\n",
       "2751                       jìr-ì jáʔ-à-nì\n",
       "2752                           jìr-ó cɛ́m\n",
       "2753                    gìd-è kúm-zɔ́ kán\n",
       "2754              gìr-ì ý kɛ́m-ɲɛ́ kárⁿ-á\n",
       "2755                                   kó\n",
       "2756                                   kó\n",
       "2757                               kày-ɛ́\n",
       "2758                                káy-è\n",
       "2759                              áŋìn-ɛ̀\n",
       "2760                                 kó-ó\n",
       "2761                                 kó-ó\n",
       "2762                         ábáb-á gúb-é\n",
       "2763                                 ày-è\n",
       "2764                               áánj-í\n",
       "2765                               háál-è\n",
       "2766                                 pó-ó\n",
       "2767                            nɔ́:rⁿí-ɔ\n",
       "2768                                ááy-ó\n",
       "2769                                 ká-á\n",
       "2770                               dáár-ì\n",
       "2771                               dààr-ì\n",
       "2772                                   kó\n",
       "2773                             áálíy-ɛ́\n",
       "2774                            wǎ:g ɛ́-á\n",
       "2783                     mìmb-ès-î tɔ́t-í\n",
       "2784                       sùs-ù nîì t-ɔ́\n",
       "2785                      sòn són-ì sɛ̂-ò\n",
       "2786                         dòɲj-é tùw-é\n",
       "2787                         dòn-jé túw-è\n",
       "2788                       dòn-jîì túúl-ò\n",
       "2789                    kàg-ù-zá kág-ú-zá\n",
       "2790                   yɔ̀r-ɔ̀: ní: tɔ́-ɔ\n",
       "2791                         sǔnd-è sw-ɛ́\n",
       "2792                      tɔ̀n-jî tɔ́n-jí\n",
       "2793                    sò:n-jì sw-ɛ́-o\n",
       "2794                    yɔ̀r-ɔ̀ ní: tɔ́-ɔ\n",
       "2795                      sò:n-jì sw-ɛ́-ò\n",
       "2796                        só:nd-í tɔ́-ó\n",
       "2797                    tùr-ɔ̀ díí túr-ɔ́\n",
       "2798                         yúl-ɔ́ tɔ́ɔ́\n",
       "2799                   tùr-ɛ̀ jììⁿ túr-ɛ́\n",
       "2800                    tùr-ɛ̀ⁿ jì tùr-ɛ́\n",
       "2801                                 t-ɔ́\n",
       "2802                          sùm-zú tó-ó\n",
       "2803                        yùùj-ǎá tɔ́-́\n",
       "2804                    m̀b-ùù nîì tóót-í\n",
       "2805                        gúl-ɔ̀ gùl-ɔ́\n",
       "2806                        gúr-ɔ̀ gùr-ɔ́\n",
       "2807                     sùnd-è jár-ì jǎr\n",
       "2808                   sùnd-è jár-ì sw-ɛ́\n",
       "2809                   nɔ̀̀ jǎár-â jǎár-í\n",
       "2810                        àŋà dád-ú gòó\n",
       "2811                    kààⁿ jìì búr-ó-mì\n",
       "2812                   kà:ⁿ jìl-ɛ̀ gw-è-à\n",
       "2813                         bùr-ú bùr-ɔ́\n",
       "2814                     kɛ̀n-ɛ̀ dǐ: gǒ-ɛ\n",
       "2815                         àŋà dǐ: gǒ-à\n",
       "2816                                bùw-á\n",
       "2817                               gúl-ɛ̀\n",
       "2818                               gùr-ɔ́\n",
       "2819                                jàr-è\n",
       "2820                               jǎár-í\n",
       "2821                            pár-i-yɛ́\n",
       "2822                        àŋà dád-ú gòó\n",
       "2823                               gùr-ɔ́\n",
       "2824                               bùr-ɔ́\n",
       "2825                          gúr-à gùr-á\n",
       "2826                        gúr-ɔ̀ gùr-ɔ́\n",
       "2827                            sûû sɛ̂-̂\n",
       "2828                              wɛ̀s-ɛ́\n",
       "2829                              wɛ́s-ɛ̀\n",
       "2830                       wèd êè wɛ̀d-ɛ́\n",
       "2831                           tɔ̌y tɔ́-ɔ\n",
       "2832                           tɔ̌y tɔ́-ɔ\n",
       "2833                          tɔ̌ y tɔ́-ɔ\n",
       "2834                                 ùl-è\n",
       "2835                              úrô úró\n",
       "2836                         sɔ́: sw-ɛ́-ɔ\n",
       "2837                        gúr-ɔ̀ gùr-ɔ́\n",
       "2838                         gúl-á gùl-ɔ́\n",
       "2839                        énj-í ɛ́nj-ɔ́\n",
       "2840                        gúr-ɔ́ gùr-ɔ́\n",
       "2841                        gúl-ɔ́ gùl-ɔ́\n",
       "2842                               gùl-ɛ̀\n",
       "2843                        gùl-ɛ́ gùl-ɛ̀\n",
       "Name: FORM, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_parsed[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dab7f-0e78-4df7-9185-cb5abb744dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a3c3b15a-6c04-44d1-8134-c8b869849765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t-ɔ́'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_parser.segment_cvcs(\"t-ɔ́\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f68cf-41fa-4f8b-b1b5-9bdcd7de0544",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Adjective_numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1dfe0d2-c2e9-4513-8384-6edc191e7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_numeral = data[(data[\"POS\"] == \"numeral\") | (data[\"POS\"] == \"adjective\")][\"SINGULAR\"]\n",
    "adjective_numeral = adjective_numeral.apply(lambda x: str(x) if isinstance(x, str) else \"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8c5e4843-7057-4e3a-94fc-76eb21db1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_num_parser=AdjectiveNumeralParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "59ac749e-6927-4b5c-b567-9d5b3980a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_adjective_numerals=adjective_numeral.apply(\n",
    "    adj_num_parser.existing_parses).apply(\n",
    "    adj_num_parser.first_parse_durationals).apply(\n",
    "    adj_num_parser.isolating_suffixes).apply(\n",
    "    adj_num_parser.y_suffixes).apply(\n",
    "    adj_num_parser.replace_hyphens_keep_last).apply(\n",
    "    adj_num_parser.switch_hyphen_position).apply(\n",
    "    adj_num_parser.miscellaneous\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "34e98c24-c25e-47ea-a74b-51b5ce10620e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "772       pɛ̌-ɛ́\n",
       "773       pɛ̌-ɛ́\n",
       "774       ʔìl-ɛ̀\n",
       "775       dìy-ɔ́\n",
       "776     dìyɔ̌-ɔ́\n",
       "777        pɛ̌-y\n",
       "778       kóór-ó\n",
       "779       pɛ́-yⁿ\n",
       "780       pɛ̌-yⁿ\n",
       "781       pɛ̌-yⁿ\n",
       "782       káán-ú\n",
       "783    kúnjɔ́-ɔ́\n",
       "784       pɛ̌-ɛ́\n",
       "785     káámn-ɔ́\n",
       "786        pɛ̌-y\n",
       "787    pɛ̀y g-ɔ́\n",
       "788       pɛ̌-ɛ́\n",
       "789       kúnj-ú\n",
       "790         pɛ̌ⁿ\n",
       "791        pɛ̌-y\n",
       "Name: SINGULAR, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_adjective_numerals[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13a311-1358-4a28-8878-9e5f2a616576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fce9b7-9063-44d8-8828-f863c0d47135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
